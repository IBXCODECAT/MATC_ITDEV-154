{{Short description|AI system capable of generating content in response to prompts}}
{{Distinguish|Artificial general intelligence}}
{{Merge|Synthetic media|date=July 2023|discuss=Talk:Generative_artificial_intelligence#Synthetic_Media_vs._Generative_Artificial_Intelligence}}
{{Use mdy dates|date=October 2023}}
[[File:Théâtre D’opéra Spatial.png|thumb|[[Théâtre d'Opéra Spatial]], an image generated by [[Midjourney]]|alt=A detailed oil painting of figures in a futuristic opera scene]]
'''Generative artificial intelligence''' (also '''generative AI''' or '''GenAI'''<ref>{{cite web |url=https://www.gov.ca.gov/wp-content/uploads/2023/09/AI-EO-No.12-_-GGN-Signed.pdf |title=Executive Order N-12-23 |publisher=Executive Department, State of California |author1=Newsom, Gavin |author2=Weber, Shirley N. |date=September 6, 2023 |accessdate=September 7, 2023}}</ref>) is [[artificial intelligence]] capable of generating text, images, or other media, using [[Generative model|generative models]].<ref name="nytimes">{{Cite web|url=https://www.nytimes.com/2023/01/27/technology/anthropic-ai-funding.html|title=Anthropic Said to Be Closing In on $300 Million in New A.I. Funding|last1=Griffith|first1=Erin|last2=Metz|first2=Cade|date=2023-01-27|work=[[The New York Times]]|accessdate=2023-03-14}}</ref><ref name="bloomberg">{{cite news |last1=Lanxon |first1=Nate |last2=Bass |first2=Dina |last3=Davalos |first3=Jackie |title=A Cheat Sheet to AI Buzzwords and Their Meanings |url=https://news.bloomberglaw.com/tech-and-telecom-law/a-cheat-sheet-to-ai-buzzwords-and-their-meanings-quicktake |access-date=March 14, 2023 |newspaper=Bloomberg News |date=March 10, 2023 |location=}}</ref><ref>{{cite arXiv |last1=Pinaya |first1=Walter H. L. |last2=Graham |first2=Mark S. |last3=Kerfoot |first3=Eric |last4=Tudosiu |first4=Petru-Daniel |last5=Dafflon |first5=Jessica |last6=Fernandez |first6=Virginia |last7=Sanchez |first7=Pedro |last8=Wolleb |first8=Julia |last9=da Costa |first9=Pedro F. |last10=Patel |first10=Ashay |title=Generative AI for Medical Imaging: extending the MONAI Framework |year=2023 |class=eess.IV |eprint=2307.15208}}</ref> Generative AI [[Generative model|models]] [[machine learning|learn]] the patterns and structure of their input [[training data set|training data]] and then generate new data that has similar characteristics.<ref name=":0">{{Cite news |last=Pasick |first=Adam |date=2023-03-27 |title=Artificial Intelligence Glossary: Neural Networks and Other Terms Explained |language=en-US |work=The New York Times |url=https://www.nytimes.com/article/ai-artificial-intelligence-glossary.html |access-date=2023-04-22 |issn=0362-4331}}</ref><ref>{{cite web | url=https://openai.com/research/generative-models | title=Generative models | author1=Andrej Karpathy | author2=Pieter Abbeel | author3=Greg Brockman | author4=Peter Chen | author5=Vicki Cheung | author6=Yan Duan | author7=Ian Goodfellow | author8=Durk Kingma | author9=Jonathan Ho | author10=Rein Houthooft | author11=Tim Salimans | author12=John Schulman | author13=Ilya Sutskever | author14=Wojciech Zaremba | date=2016-06-16 | website=OpenAI}}</ref>

In the early 2020s, advances in [[Transformer_(machine_learning_model)|transformer]]-based [[Deep learning|deep]] [[neural networks]] enabled a number of generative AI systems notable for accepting [[Prompt (natural language)|natural language prompts]] as input. These include [[large language model]] [[chatbots]] such as [[ChatGPT]], [[Bing Chat]], [[Bard (chatbot)|Bard]], and [[LLaMA]], and [[text-to-image]] [[artificial intelligence art]] systems such as [[Stable Diffusion]], [[Midjourney]], and [[DALL-E]].<ref name="nytimes-gpt4">{{Cite news |last=Metz |first=Cade |date=2023-03-14 |title=OpenAI Plans to Up the Ante in Tech's A.I. Race |language=en-US |work=The New York Times |url=https://www.nytimes.com/2023/03/14/technology/openai-gpt4-chatgpt.html |access-date=2023-03-31 |issn=0362-4331}}</ref><ref>{{Cite arXiv |last1=Thoppilan |first1=Romal |last2=De Freitas |first2=Daniel |last3=Hall |first3=Jamie |last4=Shazeer |first4=Noam |last5=Kulshreshtha |first5=Apoorv |date=January 20, 2022 |title=LaMDA: Language Models for Dialog Applications |class=cs.CL |eprint=2201.08239 <!--|url-status=live |archive-url=https://web.archive.org/web/20220121025747/https://arxiv.org/abs/2201.08239 |archive-date=January 21, 2022 |access-date=June 12, 2022-->}}</ref><ref>{{Cite web|last=Roose|first=Kevin|date=2022-10-21|title=A Coming-Out Party for Generative A.I., Silicon Valley's New Craze|url=https://www.nytimes.com/2022/10/21/technology/generative-ai.html|access-date=2023-03-14|website=[[The New York Times]]}}</ref>

Generative AI has uses across a wide range of industries, including art, writing, software development, product design, healthcare, finance, gaming, marketing, and fashion.<ref name="economist2">{{Cite web|url=https://www.economist.com/business/2023/03/06/dont-fear-an-ai-induced-jobs-apocalypse-just-yet|title=Don't fear an AI-induced jobs apocalypse just yet|date=2023-03-06|publisher=The Economist|accessdate=2023-03-14}}</ref><ref name="mckinsey">{{Cite web|url=https://www.mckinsey.com/industries/retail/our-insights/generative-ai-unlocking-the-future-of-fashion|title=Generative AI: Unlocking the future of fashion|last1=Harreis|first1=H.|last2=Koullias|first2=T.|last3=Roberts|first3=Roger}}</ref><ref>{{Cite news|date=2023-06-16|title=How Generative AI Can Augment Human Creativity|work=Harvard Business Review|url=https://hbr.org/2023/07/how-generative-ai-can-augment-human-creativity|access-date=2023-06-20|issn=0017-8012}}</ref>
Investment in generative AI surged during the early 2020s, with large companies such as Microsoft, Google, and Baidu as well as numerous smaller firms developing generative AI models.<ref name="nytimes"/><ref name="economist1">{{Cite web|url=https://www.economist.com/business/2023/01/30/the-race-of-the-ai-labs-heats-up|title=The race of the AI labs heats up|date=2023-01-30|publisher=The Economist|accessdate=2023-03-14}}</ref><ref>{{Cite web|url=https://cloud.google.com/blog/products/ai-machine-learning/generative-ai-for-businesses-and-governments|title=Google Cloud brings generative AI to developers, businesses, and governments|last1=Yang|first1=June|last2=Gokturk|first2=Burak|date=2023-03-14}}</ref> However, there are also concerns about the potential misuse of generative AI, including [[cybercrime]] or creating [[fake news]] or [[deepfake]]s which can be used to deceive or manipulate people.<ref>{{cite web |title=Transcript: Senate Judiciary Subcommittee Hearing on Oversight of AI |url=https://techpolicy.press/transcript-senate-judiciary-subcommittee-hearing-on-oversight-of-ai/ |website=techpolicy.press |author=Justin Hendrix |date=May 16, 2023 |access-date=May 19, 2023}}</ref>

==History==
{{main|History of artificial intelligence}}

The academic discipline of artificial intelligence was founded at a research [[Dartmouth workshop|workshop]] at [[Dartmouth College]] in 1956, and has experienced several waves of advancement and optimism in the decades since.<ref>{{Cite book |last=Crevier |first=Daniel |title=AI: The Tumultuous Search for Artificial Intelligence. |publisher=BasicBooks |year=1993 |isbn=0-465-02997-3 |location=New York, NY |pages=109}}</ref> Since its founding, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by [[History of artificial intelligence|myth]], [[Artificial intelligence in fiction|fiction]] and [[Philosophy of artificial intelligence|philosophy]] since antiquity.<ref>{{Cite book |last=Newquist |first=HP |title=The Brain Makers: Genius, Ego, And Greed In The Quest For Machines That Think |publisher=Macmillan/SAMS |year=1994 |isbn=978-0-672-30412-5 |location=New York |pages=45–53}}</ref> These concepts of automated art date back at least to the [[Automaton|automata]] of [[Hellenistic civilization|ancient Greek civilization]], where inventors such as [[Daedalus]] and [[Hero of Alexandria]] were described as having designed machines capable of writing text, generating sounds, and playing music.<ref>{{citation |author=Noel Sharkey |title=A programmable robot from 60 AD |date=July 4, 2007 |url=https://www.newscientist.com/blog/technology/2007/07/programmable-robot-from-60ad.html |volume=2611 |access-date=October 22, 2019 |archive-url=https://web.archive.org/web/20180113090903/https://www.newscientist.com/blog/technology/2007/07/programmable-robot-from-60ad.html |url-status=live |publisher=New Scientist |archive-date=January 13, 2018}}</ref><ref>{{Citation |last=Brett |first=Gerard |title=The Automata in the Byzantine "Throne of Solomon" |date=July 1954 |journal=Speculum |volume=29 |issue=3 |pages=477–487 |postscript=. |doi=10.2307/2846790 |issn=0038-7134 |jstor=2846790 |s2cid=163031682}}</ref>  The tradition of creative automatons has flourished throughout history, such as [[Maillardet's automaton]], created in the early 1800s.<ref>{{Cite web |last=kelinich |date=2014-03-08 |title=Maillardet's Automaton |url=https://www.fi.edu/en/history-resources/automaton |access-date=2023-08-24 |website=The Franklin Institute |language=en}}</ref>

Since the founding of AI in the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, [[Harold Cohen (artist)|Harold Cohen]] was creating and exhibiting generative AI works created by [[AARON]], the computer program Cohen created to generate paintings.<ref>{{Cite journal |last1=Bergen |first1=Nathan |last2=Huang |first2=Angela |date=2023 |title=A BRIEF HISTORY OF GENERATIVE AI |url=https://www2.deloitte.com/content/dam/Deloitte/us/Documents/consulting/us-gen-ai-dichotomies.pdf |journal=Dichotomies: Generative AI: Navigating Towards a Better Future |issue=2 |pages=4}}</ref>

[[Markov chain|Markov chains]] have long been used to model natural languages since their development by Russian mathematician [[Andrey Markov]] in the early 20th century. Markov published his first paper on the topic in 1906,<ref>{{cite book |last=Gagniuc |first=Paul A. |title=Markov Chains: From Theory to Implementation and Experimentation |publisher=John Wiley & Sons |year=2017 |isbn=978-1-119-38755-8 |location=USA, NJ |pages=2–8}}</ref><ref name="GrinsteadSnell1997page4643">{{cite book |author1=Charles Miller Grinstead |url=https://archive.org/details/flooved3489 |title=Introduction to Probability |author2=James Laurie Snell |publisher=American Mathematical Soc. |year=1997 |isbn=978-0-8218-0749-1 |pages=[https://archive.org/details/flooved3489/page/n473 464]–466}}</ref><ref name="Bremaud2013pageIX3">{{cite book |author=Pierre Bremaud |url=https://books.google.com/books?id=jrPVBwAAQBAJ |title=Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues |date=9 March 2013 |publisher=Springer Science & Business Media |isbn=978-1-4757-3124-8 |page=ix |archive-url=https://web.archive.org/web/20170323160437/https://books.google.com/books?id=jrPVBwAAQBAJ |archive-date=23 March 2017 |url-status=live}}</ref> and analyzed the pattern of vowels and consonants in the novel ''[[Eugene Onegin|Eugeny Onegin]]'' using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.<ref>{{Cite journal |last=Hayes |first=Brian |date=2013 |title=First Links in the Markov Chain |url=http://dx.doi.org/10.1511/2013.101.92 |journal=American Scientist |volume=101 |issue=2 |pages=92 |doi=10.1511/2013.101.92 |issn=0003-0996}}</ref><ref>{{Cite journal |last1=Fine |first1=Shai |last2=Singer |first2=Yoram |last3=Tishby |first3=Naftali |date=1998-07-01 |title=The Hierarchical Hidden Markov Model: Analysis and Applications |url=https://doi.org/10.1023/A:1007469218079 |journal=Machine Learning |language=en |volume=32 |issue=1 |pages=41–62 |doi=10.1023/A:1007469218079 |s2cid=3465810 |issn=1573-0565}}</ref>

The field of [[machine learning]] often uses [[statistical models]], including [[Generative_model|generative models]], to model and predict data. Beginning in the late 2000s, the emergence of [[deep learning]] drove progress and research in [[image classification]], [[speech recognition]], [[natural language processing]] and other tasks. [[Neural network|Neural networks]] in this era were typically trained as [[Discriminative_model|discriminative]] models, due to the difficulty of generative modeling.<ref>{{Cite book|title=Machine learning: discriminative and generative|author=Tony Jebara|volume=755|year=2012|publisher=Springer Science & Business Media}}</ref>

In 2014, advancements such as the [[variational autoencoder]] and [[generative adversarial network]] produced the first practical deep neural networks capable of learning generative, rather than discriminative, models of complex data such as images. These deep generative models were the first able to output not only class labels for images, but to output entire images.

In 2017, the [[Transformer_(machine_learning_model)|Transformer]] network enabled advancements in generative models, leading to the first [[generative pre-trained transformer]] (GPT) in 2018.<ref>{{cite web|url=https://github.com/openai/finetune-transformer-lm|title=finetune-transformer-lm|website=GitHub|access-date=2023-05-19}}</ref> This was followed in 2019 by [[GPT-2]] which demonstrated the ability to generalize unsupervised to many different tasks as a [[Foundation models|Foundation model]].<ref>{{Cite journal|author=Radford, Alec; Wu, Jeffrey; Child, Rewon; Luan, David; Amodei, Dario; Sutskever, Ilya; others|title=Language models are unsupervised multitask learners|journal=OpenAI Blog|volume=1|issue=8|pages=9|year=2019}}</ref>

In 2021, the release of [[DALL-E]], a transformer-based pixel generative model, followed by [[Midjourney]] and [[Stable Diffusion]] marked the emergence of practical high-quality [[artificial intelligence art]] from natural language prompts.

In March 2023, [[GPT-4]] was released. A team from Microsoft Research argued that "it could reasonably be viewed as an early (yet still incomplete) version of an [[artificial general intelligence]] (AGI) system".<ref name="Bubeck-2023">{{Cite arXiv|title=Sparks of Artificial General Intelligence: Early experiments with GPT-4|first1=Sébastien|last1=Bubeck|first2=Varun|last2=Chandrasekaran|first3=Ronen|last3=Eldan|first4=Johannes|last4=Gehrke|first5=Eric|last5=Horvitz|first6=Ece|last6=Kamar|first7=Peter|last7=Lee|first8=Yin Tat|last8=Lee|first9=Yuanzhi|last9=Li|first10=Scott|last10=Lundberg|first11=Harsha|last11=Nori|first12=Hamid|last12=Palangi|first13=Marco Tulio|last13=Ribeiro|first14=Yi|last14=Zhang|date=March 22, 2023|class=cs.CL |eprint=2303.12712}}</ref>

==Modalities==
A generative AI system is constructed by applying [[Unsupervised learning|unsupervised]] or [[Self-supervised learning|self-supervised]] [[machine learning]] to a data set. The capabilities of a generative AI system depend on the [[List of datasets for machine-learning research|modality or type]] of the data set used.

Generative AI can be either ''unimodal'' or [[Multimodal_learning|''multimodal'']]; unimodal systems take only one type of input, whereas multimodal systems can take more than one type of input.<ref>{{cite web | url=https://www.marktechpost.com/2023/03/21/a-history-of-generative-ai-from-gan-to-gpt-4/ | title=A History of Generative AI: From GAN to GPT-4 | date=21 March 2023 }}</ref> For example, one version of [[OpenAI]]'s [[GPT-4]] accepts both text and image inputs.<ref>{{cite news |title=Explainer: What is Generative AI, the technology behind OpenAI's ChatGPT? |url=https://www.reuters.com/technology/what-is-generative-ai-technology-behind-openais-chatgpt-2023-03-17/ |work=Reuters |date=March 17, 2023 |access-date=March 17, 2023}}</ref>

===Text===
{{Quote box|quote  = World knowledge in hand,<br />Infinite pages unfold,<br />Wisdom's vast, free land.| author = — [[GPT-4]], prompt <i>a haiku about Wikipedia</i> | width  = 25% | align  = right}}
Generative AI systems trained on words or [[Lexical analysis#Tokenization|word tokens]] include [[GPT-3]], [[LaMDA]], [[LLaMA]], [[BLOOM (language model)|BLOOM]], [[GPT-4]], and others (see [[Large language model#List|List of large language models]]). They are capable of [[natural language processing]], [[machine translation]], and [[natural language generation]] and can be used as [[foundation models]] for other tasks.<ref name="FoundationModels">{{Cite arXiv |last1=Bommasani |first1=R |last2=Hudson |first2=DA |last3=Adeli |first3=E |last4=Altman |first4=R |last5=Arora |first5=S |last6=von Arx |first6=S |last7=Bernstein |first7=MS |last8=Bohg |first8=J |last9=Bosselut |first9=A |last10=Brunskill |first10=E |last11=Brynjolfsson |first11=E |title=On the opportunities and risks of foundation models |year=2021 |date=2021-08-16 |class=cs.LG |eprint=2108.07258 }}</ref> Data sets include [[BookCorpus]], [[Wikipedia]], and others (see [[List of text corpora]]).

===Code===
In addition to [[natural language]] text, large language models can be trained on [[programming language]] text, allowing them to generate [[source code]] for new [[computer programs]].<ref>{{cite arXiv | last1=Chen | first1=Ming | last2=Tworek | first2=Jakub | last3=Jun | first3=Hongyu | last4=Yuan | first4=Qinyuan | last5=Pinto | first5=Hanyu Philippe De Oliveira | last6=Kaplan | first6=Jerry | last7=Edwards | first7=Haley | last8=Burda | first8=Yannick | last9=Joseph | first9=Nicholas | last10=Brockman | first10=Greg | last11=Ray | first11=Alvin | title=Evaluating Large Language Models Trained on Code | date=2021-07-06 | class=cs.LG | eprint=2107.03374}}</ref> Examples include [[OpenAI Codex]].

===Images===
[[File:Example-dog-on-the-internet.png|thumb|[[Stable Diffusion]], prompt <i>Cinematic photo of a dog on the Internet editing Wikipedia</i>]]
{{see also|Artificial intelligence art}}
Producing high-quality visual art is a prominent application of generative AI.<ref>{{cite journal |last1=Epstein |first1=Ziv |last2=Hertzmann |first2=Aaron |last3=Akten |first3=Memo |last4=Farid |first4=Hany |last5=Fjeld |first5=Jessica |last6=Frank |first6=Morgan R. |last7=Groh |first7=Matthew |last8=Herman |first8=Laura |last9=Leach |first9=Neil |last10=Mahari |first10=Robert |last11=Pentland |first11=Alex “Sandy” |last12=Russakovsky |first12=Olga |last13=Schroeder |first13=Hope |last14=Smith |first14=Amy |title=Art and the science of generative AI |journal=[[Science (journal)|Science]] |date=2023 |volume=380 |issue=6650 |pages=1110–1111 |doi=10.1126/science.adh4451|pmid=37319193 |arxiv=2306.04141 |bibcode=2023Sci...380.1110E |s2cid=259095707 }}</ref> Many such artistic works have received public [[Artificial_intelligence_art#Awards_and_recognition|awards and recognition]].

Generative AI systems trained on sets of images with [[Caption (text)|text captions]] include [[Google Brain|Imagen]], [[DALL-E]], [[Midjourney]], [[Adobe Firefly]], [[Stable Diffusion]] and others (see [[Artificial intelligence art]], [[Generative art]], and [[Synthetic media]]). They are commonly used for [[Text-to-image model|text-to-image]] generation and [[neural style transfer]].<ref name="ZeroShotTextToImage">{{Cite conference |last1=Ramesh |first1=Aditya |last2=Pavlov |first2=Mikhail |last3=Goh |first3=Gabriel |last4=Gray |first4=Scott |last5=Voss |first5=Chelsea |last6=Radford |first6=Alec |last7=Chen |first7=Mark |last8=Sutskever |first8=Ilya |title=Zero-shot text-to-image generation |book-title=International Conference on Machine Learning |pages=8821–8831 |year=2021 |publisher=PMLR }}</ref> Datasets include [[LAION|LAION-5B]] and others (See [[:Category:Datasets in computer vision|Datasets in computer vision]]).

===Music===
[[File:Encyclopedic-Synth-Pop-Loop.oga|thumb|MusicGen, prompt <i>encyclopedic synth pop track with bassy drums and neutral point of view</i>]]Generative AI systems such as MusicLM<ref>{{cite arXiv|last1=Agostinelli|first1=Andrea|last2=Denk|first2=Timo I.|last3=Borsos|first3=Zalán|last4=Engel|first4=Jesse|last5=Verzetti|first5=Mauro|last6=Caillon|first6=Antoine|last7=Huang|first7=Qingqing|last8=Jansen|first8=Aren|last9=Roberts|first9=Adam|last10=Tagliasacchi|first10=Marco|last11=Sharifi|first11=Matt|last12=Zeghidour|first12=Neil|last13=Frank|first13=Christian|title=MusicLM: Generating Music From Text|eprint=2301.11325|date=26 January 2023|class=cs.SD }}</ref> and MusicGen<ref>{{Cite web|url=https://www.musicbusinessworldwide.com/meet-audiocraft-metas-new-generative-ai-tool-for-audio-and-music/|title=Meta in June said that it used 20,000 hours of licensed music to train MusicGen, which included 10,000 "high-quality" licensed music tracks. At the time, Meta's researchers outlined in a paper the ethical challenges that they encountered around the development of generative AI models like MusicGen.|last=Dalugdug|first=Mandy|date=August 3, 2023|access-date=}}</ref> can be trained on the audio waveforms of recorded music along with text annotations, in order to generate new musical samples based on text descriptions such as ''a calming violin melody backed by a distorted guitar riff''.

===Video===
[[File:Gen2-Example-Dog-Podium.webm|thumb|Runway Gen2, prompt <i>A golden retriever in a suit sitting at a podium giving a speech to the white house press corps</i>]]Generative AI trained on annotated video can generate temporally-coherent video clips. Examples include Gen1 and Gen2 by RunwayML<ref>{{cite web|last=Metz|first=Cade|title=Instant Videos Could Represent the Next Leap in A.I. Technology|url=https://www.nytimes.com/2023/04/04/technology/runway-ai-videos.html|website=The New York Times|date=April 4, 2023|language=en}}</ref> and Make-A-Video by [[Meta Platforms]].<ref>{{cite web|url=https://www.cnet.com/news/social-media/facebook-parent-metas-ai-tool-can-create-artsy-videos-from-text/|title=Facebook Parent Meta's AI Tool Can Create Artsy Videos From Text|author=Queenie Wong|date=Sep 29, 2022|publisher=cnet.com|accessdate=Apr 4, 2023}}</ref>

===Molecules===
Generative AI systems can be trained on sequences of [[amino acids]] or molecular representations such as [[Simplified molecular-input line-entry system|SMILES]] representing DNA or proteins. These systems, such as [[AlphaFold]], are used for [[protein structure prediction]] and [[drug discovery]].<ref name="MITTechReview-AI-Automation">{{Cite web |last=Heaven |first=Will Douglas |title=AI is dreaming up drugs that no one has ever seen. Now we've got to see if they work |url=https://www.technologyreview.com/2023/02/15/1067904/ai-automation-drug-development/ |website=MIT Technology Review |publisher=Massachusetts Institute of Technology |date=2023-02-15 |access-date=2023-03-15 }}</ref> Datasets include [[List of biological databases|various biological datasets]].

=== Robotics ===
Generative AI can also be trained on the motions of a [[robotic]] system to generate new trajectories for [[motion planning]] or [[Robot_navigation|navigation]]. For example, UniPi from Google Research uses prompts like ''"pick up blue bowl"'' or ''"wipe plate with yellow sponge"'' to control movements of a robot arm.<ref>{{cite web|url=https://ai.googleblog.com/2023/04/unipi-learning-universal-policies-via.html|title=UniPi: Learning universal policies via text-guided video generation|date=2023-04-12|author=Sherry Yang, Yilun Du|work=Google Research, Brain Team|publisher=Google AI Blog|access-date=}}</ref> Multimodal "vision-language-action" models such as Google's RT-2 can perform rudimentary reasoning in response to user prompts and visual input, such as picking up a toy [[dinosaur]] when given the prompt <i>pick up the extinct animal</i> at a table filled with toy animals and other objects.<ref>{{cite arXiv| last = Brohan| first = Anthony| author-link = et al.| date = 2023| title = RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control| eprint = 2307.15818 | class = cs.RO}}</ref>

=== Planning ===
The terms '''generative AI planning''' or '''generative planning''' were used in the 1980s and 1990s to refer to [[AI planning]] systems, especially [[computer-aided process planning]], used to generate sequences of actions to reach a specified goal.<ref name="alting">{{cite journal|last1=Alting|first1=Leo|last2=Zhang|first2=Hongchao|title=Computer aided process planning: the state-of-the-art survey|journal=The International Journal of Production Research|volume=27|issue=4|year=1989|pages=553–585|doi=10.1080/00207548908942569 |url=https://www.researchgate.net/publication/236649325}}</ref><ref>{{Cite journal|last=Chien|first=Steve|title=Automated planning and scheduling for goal-based autonomous spacecraft|journal=IEEE Intelligent Systems and Their Applications|volume=13|issue=5|year=1998|pages=50–55|doi=10.1109/5254.722362 }}</ref>

Generative AI planning systems used [[symbolic AI]] methods such as [[state space search]] and [[constraint satisfaction]] and were a "relatively mature" technology by the early 1990s. They were used to generate crisis action plans for military use,<ref>{{Cite book |title=ARPA/Rome Laboratory Knowledge-based Planning and Scheduling Initiative Workshop Proceedings |publisher=The Advanced Research Projects Agency, Department of Defense, and Rome Laboratory, US Air Force, Griffiss AFB |year=1994 |isbn=155860345X |editor-last=Burstein |editor-first=Mark H. |pages=219}}</ref> process plans for manufacturing<ref name="alting"/> and decision plans such as in prototype autonomous spacecraft.<ref>{{cite book|last1=Pell|first1=Barney|last2=Bernard|first2=Douglas E.|last3=Chien|first3=Steve A.|last4=Gat|first4=Erann|last5=Muscettola|first5=Nicola|last6=Nayak|first6=P. Pandurang|last7=Wagner|first7=Michael D.|last8=Williams|first8=Brian C.|title=An Autonomous Spacecraft Agent Prototype|editor1-last=Bekey|editor1-first=George A.|year=1998|publisher=Autonomous Robots Volume 5, No. 1|pages=29–45|quote=Our deliberator is a traditional generative AI planner based on the HSTS planning framework (Muscettola, 1994), and our control component is a traditional spacecraft attitude control system (Hackney et al. 1993). We also add an architectural component explicitly dedicated to world modeling (the mode identifier), and distinguish between control and monitoring.}}</ref>

==Software and hardware==
Generative AI models are used to power [[chatbot]] products such as [[ChatGPT]], [[programming tools]] such as [[GitHub Copilot]],<ref>{{Cite web |url=https://www.axios.com/2023/06/30/githubs-vision-to-make-code-more-secure-by-design |title=GitHub has a vision to make code more secure by design |last=Sabin |first=Sam |date=2023-06-30 |website=Axios Codebook |access-date=2023-08-15}}</ref> [[Text-to-image model|text-to-image]] products such as [[Midjourney]], and text-to-video products such as Runway Gen-2.<ref>{{cite web|url=https://www.theverge.com/2023/3/20/23648113/text-to-video-generative-ai-runway-ml-gen-2-model-access|title=Text-to-video AI inches closer as startup Runway announces new model|author=James Vincent|work=The Verge|date=Mar 20, 2023|access-date=2023-08-15|quote=Text-to-video is the next frontier for generative AI, though current output is rudimentary. Runway says it’ll be making its new generative video model, Gen-2, available to users in ‘the coming weeks.’}}</ref> Generative AI features have been integrated into a variety of existing commercially-available products such as [[Microsoft Office]],<ref>{{Cite web|url=https://www.cnbc.com/2023/03/16/microsoft-to-improve-office-365-with-chatgpt-like-generative-ai-tech-.html |title=Microsoft adds OpenAI technology to Word and Excel |last=Vanian |first=Jonathan |date=2023-03-16 |accessdate=2023-08-15 |publisher=CNBC |quote=Microsoft is bringing generative artificial intelligence technologies such as the popular ChatGPT chatting app to its Microsoft 365 suite of business software....the new A.I. features, dubbed Copilot, will be available in some of the company's most popular business apps, including Word, PowerPoint and Excel. }}</ref> [[Google Photos]],<ref>{{cite web|url=https://www.techradar.com/computing/software/google-photos-now-shows-you-an-ai-powered-highlights-reel-of-your-life|title=The app's Memories feature just got a big upgrade|author=Mark Wilson|date=2023-08-15|work=TechRadar|access-date=|quote=The Google Photos app is getting a redesigned, AI-powered Memories feature...you'll be able to use generative AI to come up with some suggested names like "a desert adventure".}}</ref> and [[Adobe Photoshop]].<ref>{{cite web|url=https://www.mediapost.com/publications/article/385660/adobe-adds-generative-ai-to-photoshop.html |title=Adobe Adds Generative AI To Photoshop |first=Laurie |last=Sullivan |date=May 23, 2023 |accessdate=2023-08-15 |work=MediaPost |quote=Generative artificial intelligence (AI) will become one of the most important features for creative designers and marketers. Adobe on Tuesday unveiled a Generative Fill feature in Photoshop to bring Firefly's AI capabilities into design.}}</ref>  Many generative AI models are also available as [[open-source software]], including [[Stable Diffusion]] and the [[LLaMA]]<ref>{{cite web|url=https://venturebeat.com/ai/llama-2-how-to-access-and-use-metas-versatile-open-source-chatbot-right-now/ |title=LLaMA 2: How to access and use Meta's versatile open-source chatbot right now |author=Michael Nuñez |date=July 19, 2023 |accessdate=2023-08-15 |website=VentureBeat |quote=If you want to run LLaMA 2 on your own machine or modify the code, you can download it directly from Hugging Face, a leading platform for sharing AI models.}}</ref> language model.

Smaller generative AI models with up to a few billion parameters can run on [[smartphones]], embedded devices, and [[personal computers]]. For example, [[LLaMA]]-7B (a version with 7 billion parameters) can run on a Raspberry Pi 4<ref>{{cite web|url=https://www.tomshardware.com/how-to/create-ai-chatbot-server-on-raspberry-pi |title=How To Create Your Own AI Chatbot Server With Raspberry Pi 4 |last=Pounder |first=Les |date=2023-03-25 |accessdate=2023-08-15 |publisher= |quote=Using a Pi 4 with 8GB of RAM, you can create a ChatGPT-like server based on LLaMA.}}</ref> and one version of [[Stable Diffusion]] can run on an [[iPhone 11]].<ref>{{cite web |url=https://the-decoder.com/draw-things-app-brings-stable-diffusion-to-the-iphone/ |title="Draw Things" App brings Stable Diffusion to the iPhone |last=Kemper |first=Jonathan |date=Nov 10, 2022 |website=The Decoder |quote=Draw Things is an app that brings Stable Diffusion to the iPhone. The AI images are generated locally, so you don't need an Internet connection. |accessdate=2023-08-15 }}</ref>

Larger models with tens of billions of parameters can run on [[laptop]] or [[desktop computers]]. To achieve an acceptable speed, models of this size may require [[AI accelerator|accelerators]] such as the [[GPU]] chips produced by [[Nvidia]] and [[AMD]] or the Neural Engine included in [[Apple silicon]] products. For example, the 65 billion parameter version of [[LLaMA]] can be configured to run on a desktop PC.<ref>{{cite web|url=https://www.hardware-corner.net/guides/computer-to-run-llama-ai-model/|title=Best Computer to Run LLaMA AI Model at Home (GPU, CPU, RAM, SSD)|date=2023-07-07|author=Allan Witt|quote=To run LLaMA model at home, you will need a computer build with a powerful GPU that can handle the large amount of data and computation required for inferencing.}}</ref>

Language models with hundreds of billions of parameters, such as [[GPT-4]] or [[PaLM]], typically run on [[datacenter]] computers equipped with arrays of [[GPUs]] (such as Nvidia's [[Hopper_(microarchitecture)|H100]]) or [[AI accelerator]] chips (such as Google's [[Tensor Processing Unit|TPU]]). These very large models are typically accessed as [[Cloud computing|cloud]] services over the Internet.

In 2022, the [[United States New Export Controls on Advanced Computing and Semiconductors to China]] imposed restrictions on exports to China of [[GPU]] and [[AI accelerator]] chips used for generative AI.<ref>{{Cite web|url=https://www.reuters.com/technology/nvidia-says-us-has-imposed-new-license-requirement-future-exports-china-2022-08-31/ |title=U.S. officials order Nvidia to halt sales of top AI chips to China |last1=Nellis |first1=Stephen |last2=Lee |first2=Jane |date=September 1, 2022 |website=Reuters |access-date=2023-08-15}}</ref> Chips such as the Nvidia A800<ref>{{cite web|url=https://www.tomshardware.com/news/nvidia-a800-performance-revealed |title=Nvidia's Chinese A800 GPU's Performance Revealed |first=Anton |last=Shilov |date=2023-05-07 |publisher=Tom's Hardware |access-date=2023-08-15 |quote=the A800 operates at 70% of the speed of A100 GPUs while complying with strict U.S. export standards that limit how much processing power Nvidia can sell.}}</ref> and the [[Biren Technology]] BR104<ref>{{cite web |url=https://www.semianalysis.com/p/how-chinas-biren-is-attempting-to |title=How China's Biren Is Attempting To Evade US Sanctions |author=Dylan Patel |date=October 24, 2022 |accessdate=August 15, 2023}}</ref> were developed to meet the requirements of the sanctions.

==Concerns==
{{See also|Ethics of artificial intelligence|Existential risk from artificial general intelligence}}

The development of generative AI has raised concerns from governments, businesses, and individuals, resulting in protests, legal actions, calls to [[Pause_Giant_AI_Experiments:_An_Open_Letter|pause AI experiments]], and actions by multiple governments. In a July 2023 briefing of the [[United Nations Security Council]], [[Secretary-General_of_the_United_Nations|Secretary-General]] [[António Guterres]] stated "Generative AI has enormous potential for good and evil at scale", that AI may "turbocharge global development" and contribute between $10 and $15 trillion to the global economy by 2030, but that its malicious use "could cause horrific levels of death and destruction, widespread trauma, and deep psychological damage on an unimaginable scale".<ref>{{Cite web |date=18 July 2023 |title=Secretary-General's remarks to the Security Council on Artificial Intelligence |url=https://www.un.org/sg/en/content/sg/statement/2023-07-18/secretary-generals-remarks-the-security-council-artificial-intelligence-bilingual-delivered-scroll-down-for-all-english |access-date=27 July 2023 |website=un.org}}</ref>

=== Job losses ===
[[File:AI Protest Sign 2023 WGA Strike.jpg|thumb|A picketer at the [[2023 Writers Guild of America strike]]. While not a top priority, one of the WGA's 2023 requests was "regulations around the use of (generative) AI".<ref>{{cite magazine |date=4 May 2023 |title=The Writers Strike Is Taking a Stand on AI |url=https://time.com/6277158/writers-strike-ai-wga-screenwriting/ |magazine=[[Time (magazine)|Time]] |language=en |access-date=11 June 2023}}</ref>]]{{Main|Workplace impact of artificial intelligence|Technological unemployment}}
From the early days of the development of AI there have been arguments put forward by [[ELIZA]] creator [[Joseph Weizenbaum]] and others about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculations and qualitative, value-based judgements.<ref>{{Cite news |last=Tarnoff |first=Ben |date=4 August 2023 |title=Lessons from Eliza |pages=34–9 |work=[[The Guardian Weekly]]}}</ref> In April 2023, it was reported that image generation AI has resulted in 70% of the jobs for video game illustrators in China being lost.<ref>{{Cite web |last=Zhou |first=Viola |date=2023-04-11 |title=AI is already taking video game illustrators' jobs in China |url=https://restofworld.org/2023/ai-image-china-video-game-layoffs/ |access-date=2023-08-17 |website=Rest of World |language=en-US}}</ref><ref>{{Cite web |last=Carter |first=Justin |date=2023-04-11 |title=China's game art industry reportedly decimated by growing AI use |url=https://www.gamedeveloper.com/art/china-s-game-art-industry-reportedly-decimated-ai-art-use |access-date=2023-08-17 |website=Game Developer |language=en}}</ref> In July 2023, developments in generative AI contributed to the [[2023 Hollywood labor disputes]]. [[Fran Drescher]], president of the [[Screen Actors Guild]], declared that "artificial intelligence poses an [[existential threat]] to creative professions" during the [[2023 SAG-AFTRA strike]].<ref>{{cite web |last=Collier |first=Kevin |date=July 14, 2023 |title=Actors vs. AI: Strike brings focus to emerging use of advanced tech |url=https://www.nbcnews.com/tech/tech-news/hollywood-actor-sag-aftra-ai-artificial-intelligence-strike-rcna94191 |publisher=NBC News |quote=SAG-AFTRA has joined the Writer's{{sic |nolink=yes}} Guild of America in demanding a contract that explicitly demands AI regulations to protect writers and the works they create.&nbsp;... The future of generative artificial intelligence in Hollywood — and how it can be used to replace labor — has become a crucial sticking point for actors going on strike. In a news conference Thursday, Fran Drescher, president of the Screen Actors Guild-American Federation of Television and Radio Artists (more commonly known as SAG-AFTRA), declared that 'artificial intelligence poses an existential threat to creative professions, and all actors and performers deserve contract language that protects them from having their identity and talent exploited without consent and pay.'}}</ref>

=== Deepfakes ===
{{Main|Deepfake}}
Deepfakes (a [[portmanteau]] of "[[deep learning]]" and "fake"<ref name="FoxNews2018">{{Cite news |last=Brandon |first=John |date=2018-02-16 |title=Terrifying high-tech porn: Creepy 'deepfake' videos are on the rise |language=en-US |work=Fox News |url=http://www.foxnews.com/tech/2018/02/16/terrifying-high-tech-porn-creepy-deepfake-videos-are-on-rise.html |url-status=live |access-date=2018-02-20 |archive-url=https://web.archive.org/web/20180615160819/http://www.foxnews.com/tech/2018/02/16/terrifying-high-tech-porn-creepy-deepfake-videos-are-on-rise.html |archive-date=2018-06-15}}</ref>) are AI-generated media that take a person in an existing image or video and replace them with someone else's likeness using [[Artificial neural network|artificial neural networks]].<ref name=":3">{{cite web |last=Cole |first=Samantha |date=24 January 2018 |title=We Are Truly Fucked: Everyone Is Making AI-Generated Fake Porn Now |url=https://www.vice.com/en_us/article/bjye8a/reddit-fake-porn-app-daisy-ridley |url-status=live |archive-url=https://web.archive.org/web/20190907194524/https://www.vice.com/en_us/article/bjye8a/reddit-fake-porn-app-daisy-ridley |archive-date=7 September 2019 |access-date=4 May 2019 |website=Vice}}</ref> Deepfakes have garnered widespread attention and concerns for their uses in [[Deepfake pornography|deepfake celebrity pornographic videos]], [[revenge porn]], [[fake news]], [[Hoax|hoaxes]], and [[Accounting scandals|financial fraud]].<ref name="HighSnobiety2018">{{Cite news |date=2018-02-20 |title=What Are Deepfakes & Why the Future of Porn is Terrifying |language=en-US |work=Highsnobiety |url=https://www.highsnobiety.com/p/what-are-deepfakes-ai-porn/ |url-status=live |access-date=2018-02-20 |archive-url=https://web.archive.org/web/20210714032914/https://www.highsnobiety.com/p/what-are-deepfakes-ai-porn/ |archive-date=2021-07-14}}</ref><ref>{{cite web |title=Experts fear face swapping tech could start an international showdown |url=https://theoutline.com/post/3179/deepfake-videos-are-freaking-experts-out |url-status=live |archive-url=https://web.archive.org/web/20200116140157/https://theoutline.com/post/3179/deepfake-videos-are-freaking-experts-out |archive-date=2020-01-16 |access-date=2018-02-28 |website=The Outline |language=en}}</ref><ref>{{Cite news |last=Roose |first=Kevin |date=2018-03-04 |title=Here Come the Fake Videos, Too |language=en-US |work=The New York Times |url=https://www.nytimes.com/2018/03/04/technology/fake-videos-deepfakes.html |url-status=live |access-date=2018-03-24 |archive-url=https://web.archive.org/web/20190618203019/https://www.nytimes.com/2018/03/04/technology/fake-videos-deepfakes.html |archive-date=2019-06-18 |issn=0362-4331}}</ref><ref>{{cite arXiv |eprint=1910.03810 |class=cs.LG |first1=Marco |last1=Schreyer |first2=Timur |last2=Sattarov |title=Adversarial Learning of Deepfakes in Accounting |language=en |last3=Reimer |first3=Bernd |last4=Borth |first4=Damian |year=2019}}</ref> This has elicited responses from both industry and government to detect and limit their use.<ref name=":21">{{Cite web |title=Join the Deepfake Detection Challenge (DFDC) |url=https://deepfakedetectionchallenge.ai/ |url-status=live |archive-url=https://web.archive.org/web/20200112102819/https://deepfakedetectionchallenge.ai/ |archive-date=2020-01-12 |access-date=2019-11-08 |website=deepfakedetectionchallenge.ai}}</ref><ref name=":5">{{Cite web |last=Clarke |first=Yvette D. |date=2019-06-28 |title=H.R.3230 - 116th Congress (2019-2020): Defending Each and Every Person from False Appearances by Keeping Exploitation Subject to Accountability Act of 2019 |url=https://www.congress.gov/bill/116th-congress/house-bill/3230 |url-status=live |archive-url=https://web.archive.org/web/20191217110329/https://www.congress.gov/bill/116th-congress/house-bill/3230 |archive-date=2019-12-17 |access-date=2019-10-16 |website=www.congress.gov}}</ref>

===Cybercrime===

Generative AI's ability to create realistic fake content has been exploited in numerous types of cybercrime, including [[phishing]] scams.<ref>{{Cite news |last=Sjouwerman |first=Stu |date=2022-12-26 |title=Deepfakes: Get ready for phishing 2.0 |work=[[Fast Company]] |url=https://www.fastcompany.com/90829233/deepfakes-get-ready-for-phishing-2-0 |access-date=2023-07-31}}</ref> Deepfake video and audio have been used to create disinformation and fraud. Former Google fraud czar [[Shuman Ghosemajumder]] has predicted that while deepfake videos initially created a stir in the media, they would soon become commonplace, and as a result, more dangerous.<ref>{{Cite web |last=Sonnemaker |first=Tyler |title=As social media platforms brace for the incoming wave of deepfakes, Google's former 'fraud czar' predicts the biggest danger is that deepfakes will eventually become boring |url=https://www.businessinsider.com/google-ex-fraud-czar-danger-of-deepfakes-is-becoming-boring-2020-1 |access-date=2023-07-31 |website=Business Insider |language=en-US}}</ref> Cybercriminals have created large language models focused on fraud, including WormGPT and FraudGPT.<ref>{{Cite web |title=After WormGPT, FraudGPT Emerges to Help Scammers Steal Your Data |url=https://www.pcmag.com/news/after-wormgpt-fraudgpt-emerges-to-help-scammers-steal-your-data |access-date=2023-07-31 |website=PCMAG |language=en}}</ref>

===Misuse in journalism===
In January 2023, ''Futurism.com'' broke the story that [[CNET]] had been using an undisclosed internal AI tool to write at least 77 of its stories; after the news broke, CNET posted corrections to 41 of the stories.<ref>{{cite news |last1=Roth |first1=Emma |title=CNET found errors in more than half of its AI-written stories |url=https://www.theverge.com/2023/1/25/23571082/cnet-ai-written-stories-errors-corrections-red-ventures |access-date=17 June 2023 |work=[[The Verge]] |date=25 January 2023}}</ref>

In April 2023, German tabloid ''[[Die Aktuelle]]'' published a fake AI-generated interview with former racing driver [[Michael Schumacher]], who had not made any public appearances since 2013 after sustaining a brain injury in a skiing accident. The story included two possible disclosures: the cover included the line "deceptively real", and the interview included an acknowledgement at the end that it was AI-generated. The editor-in-chief was fired shortly thereafter amid the controversy.<ref>{{cite news |title=A magazine touted Michael Schumacher's first interview in years. It was actually AI |url=https://www.npr.org/2023/04/28/1172473999/michael-schumacher-ai-interview-german-magazine |access-date=17 June 2023 |work=NPR |date=28 April 2023}}</ref>

===Regulation===
{{Main article|Regulation of artificial intelligence}}
In the European Union, the proposed [[Artificial Intelligence Act]] includes requirements to disclose copyrighted material used to train generative AI systems, and to label any AI-generated output as such.<ref>{{cite news|last1=Chee|first1=Foo Yun|last2=Mukherjee|first2=Supantha|title=EU lawmakers vote for tougher AI rules as draft moves to final stage|url=https://www.reuters.com/technology/eu-lawmakers-agree-changes-draft-artificial-intelligence-rules-2023-06-14/|website=Reuters|date=June 14, 2023 |access-date=July 26, 2023|language=en}}</ref>

In the United States, a group of companies including OpenAI, Alphabet, and Meta signed a voluntary agreement with the White House in July 2023 to watermark AI-generated content.<ref>{{cite news|last1=Bartz|first1=Diane|last2=Hu|first2=Krystal|title=OpenAI, Google, others pledge to watermark AI content for safety, White House says|date=July 21, 2023 |url=https://www.reuters.com/technology/openai-google-others-pledge-watermark-ai-content-safety-white-house-2023-07-21/|work=Reuters|access-date=}}</ref>

In China, the [[Interim Measures for the Management of Generative AI Services]] introduced by the [[Cyberspace Administration of China]] regulates any public-facing generative AI. It includes requirements to watermark generated images or videos, regulations on training data and label quality, restrictions on personal data collection, and a guideline that generative AI must "adhere to socialist core values".<ref>{{Cite web|url=https://www.reuters.com/technology/china-issues-temporary-rules-generative-ai-services-2023-07-13/|title=China says generative AI rules to apply only to products for the public|last=Ye|first=Josh|date=2023-07-13|website=Reuters|access-date=2023-07-13}}</ref><ref>{{Cite web|url=http://www.cac.gov.cn/2023-07/13/c_1690898327029107.htm|title=生成式人工智能服务管理暂行办法|date=2023-07-13}}</ref>

== See also ==
* {{annotated link|Artificial general intelligence}}
* {{annotated link|Artificial imagination}}
* {{annotated link|Artificial intelligence art}}
* {{annotated link|Computational creativity}}
* {{annotated link|Generative adversarial network}}
* {{annotated link|Generative pre-trained transformer}}
* {{annotated link|Large language model}}
* {{annotated link|Music and artificial intelligence}}
* {{annotated link|Procedural generation}}
* {{anli|Stochastic parrot}}

==References==
{{Reflist}}

[[Category:Artificial intelligence]]
[[Category:Artificial neural networks]]
[[Category:Deep learning]]
[[Category:Emerging technologies]]
[[Category:Machine learning]]
[[Category:Generative artificial intelligence| ]]
